# ãƒˆãƒ¼ã‚¯ãƒ³é•·åˆ†æ V2 - æ”¹å–„ç‰ˆ

## ğŸ¯ ä¸»ãªæ”¹å–„ç‚¹

1. **è‡ªå‹•è¨­å®šèª­ã¿è¾¼ã¿**: `experiments_config.py` ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•å–å¾—
2. **åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: chrFã€COMETã‚’è¨ˆç®—ï¼ˆAccuracyã‚‚å†…éƒ¨ã§è¨ˆç®—ï¼‰
3. **çµ±åˆå¯è¦–åŒ–**: chrFã¨COMETã‚’1ã¤ã®å›³ã§æ¯”è¼ƒ
4. **ç´°ã‹ã„ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²**: 0-5, 5-10, 10-15, 15-20 ãƒˆãƒ¼ã‚¯ãƒ³
5. **æ—¢å­˜å®Ÿè£…åˆ©ç”¨**: `core.task_vectors`ã®ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡ºãƒ»æ³¨å…¥ã‚’åˆ©ç”¨

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. å®Ÿè¡Œï¼ˆãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰ï¼‰

```bash
cd /home/yukaalive/2025workspace/task_vectors/21_icl_task_vectors/21_icl_task_vectors

# å®Ÿè¡Œï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
./run_token_analysis_v2.sh
```

ã¾ãŸã¯ã€condaç’°å¢ƒã§ç›´æ¥å®Ÿè¡Œï¼š

```bash
conda run -n icl_task_vectors python -u -m scripts.experiments.token_length_analysis_v2
```

### 2. é€²æ—ç¢ºèª

```bash
# å®Œäº†ã—ãŸå®Ÿé¨“æ•°ã‚’ç¢ºèª
ls outputs/results/main/token_length_analysis_v2/*.pkl | wc -l

# ãƒ­ã‚°ã‚’ç›£è¦–
tail -f logs/token_length_analysis_v2_*.log
```

### 3. å¯è¦–åŒ–ï¼ˆå®Ÿé¨“å®Œäº†å¾Œï¼‰

```bash
python -m scripts.experiments.visualize_token_length_unified --experiment-id token_length_analysis_v2
```

## ğŸ“Š ç”Ÿæˆã•ã‚Œã‚‹å‡ºåŠ›

### çµæœãƒ•ã‚¡ã‚¤ãƒ«
```
outputs/results/main/token_length_analysis_v2/
â”œâ”€â”€ <model>_<task>.pkl  (å„å®Ÿé¨“ã®çµæœ)
```

### å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«
```
outputs/results/main/token_length_analysis_v2/
â”œâ”€â”€ unified_comparison_all_metrics.png     # çµ±åˆæ¯”è¼ƒå›³ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
â”œâ”€â”€ heatmaps_all_metrics.png               # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
â”œâ”€â”€ comparison_range_*.png                 # ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²åˆ¥æ¯”è¼ƒ
â”œâ”€â”€ summary_by_token_range.csv             # ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²åˆ¥ã‚µãƒãƒªãƒ¼
â”œâ”€â”€ summary_by_task.csv                    # ã‚¿ã‚¹ã‚¯åˆ¥ã‚µãƒãƒªãƒ¼
â”œâ”€â”€ summary_by_model.csv                   # ãƒ¢ãƒ‡ãƒ«åˆ¥ã‚µãƒãƒªãƒ¼
â””â”€â”€ all_results.csv                        # å…¨çµæœ
```

## ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®èª¬æ˜

### chrF
- Character-level F-score
- æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®é¡ä¼¼åº¦ã‚’è©•ä¾¡
- 0-1ã®ç¯„å›²ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
- å®Œå…¨ä¸€è‡´ã§ãªã„ç¿»è¨³ã‚‚é©åˆ‡ã«è©•ä¾¡

### COMET
- ç¿»è¨³ã‚¿ã‚¹ã‚¯ã®ã¿
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ç¿»è¨³è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ã„
- 0-1ã®ç¯„å›²ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰

**æ³¨**: Accuracyã¯å†…éƒ¨ã§è¨ˆç®—ã•ã‚Œã¾ã™ãŒã€chrFã¨COMETãŒã‚ˆã‚Šé©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã®ãŸã‚ã€å¯è¦–åŒ–ã§ã¯ã“ã®2ã¤ã®ã¿ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²ã®å¤‰æ›´

`scripts/experiments/token_length_analysis_v2.py` ã® `main()` é–¢æ•°ï¼š

```python
run_all_experiments(
    token_ranges=[(0, 5), (5, 10), (10, 15), (15, 20)],  # â† ã“ã“ã‚’å¤‰æ›´
    experiment_id="token_length_analysis_v2"
)
```

### ãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã®å¤‰æ›´

`core/experiments_config.py` ã‚’ç·¨é›†ï¼š

```python
MODELS_TO_EVALUATE = [
    ("swallow", "7B"),
    ("llama", "7B"),
    # è¿½åŠ ãƒ»å‰Šé™¤å¯èƒ½
]

TASKS_TO_EVALUATE = [
    "translation_ja_en_jesc",
    "translation_en_ja_jesc",
    # è¿½åŠ ãƒ»å‰Šé™¤å¯èƒ½
]
```

## ğŸ“– ä½¿ç”¨ä¾‹

### ä¾‹1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ

```bash
./run_token_analysis_v2.sh
```

ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã§è‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

### ä¾‹2: ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“ID

```python
# token_length_analysis_v2.py ã‚’ç·¨é›†
run_all_experiments(
    token_ranges=[(0, 5), (5, 10), (10, 15), (15, 20)],
    experiment_id="my_custom_experiment"  # â† ã‚«ã‚¹ã‚¿ãƒ ID
)
```

```bash
# å¯è¦–åŒ–æ™‚ã‚‚åŒã˜IDã‚’æŒ‡å®š
python -m scripts.experiments.visualize_token_length_unified --experiment-id my_custom_experiment
```

## ğŸ¨ å¯è¦–åŒ–ã®ç‰¹å¾´

### unified_comparison_all_metrics.pngï¼ˆãƒ¡ã‚¤ãƒ³å›³ï¼‰

- **ç¸¦è»¸**: ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²ï¼ˆ0-5, 5-10, 10-15, 15-20ï¼‰
- **æ¨ªè»¸**: 2ã¤ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆchrF, COMETï¼‰
- **ãƒãƒ¼**: ICLï¼ˆé’ï¼‰vs Task Vectorï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
- **æ¯”è¼ƒ**: ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«Ã—ã‚¿ã‚¹ã‚¯ã®çµ„ã¿åˆã‚ã›

### heatmaps_all_metrics.png

- **è¡Œ**: ã‚¿ã‚¹ã‚¯
- **åˆ—**: ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²
- **è‰²**: ã‚¹ã‚³ã‚¢ï¼ˆèµ¤ã„ã»ã©é«˜ã„ï¼‰
- **åˆ†å‰²**: ICL vs Task Vector

### comparison_range_*.png

- å„ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²ã”ã¨ã®è©³ç´°æ¯”è¼ƒ
- chrFã¨COMETã‚’ä¸¦ã¹ã¦è¡¨ç¤º

## â±ï¸ å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

- **1å®Ÿé¨“**: 30-60ç§’
- **å…¨å®Ÿé¨“**: `ãƒ¢ãƒ‡ãƒ«æ•° Ã— ã‚¿ã‚¹ã‚¯æ•° Ã— å®Ÿé¨“æ™‚é–“`
  - ä¾‹: 3ãƒ¢ãƒ‡ãƒ« Ã— 6ã‚¿ã‚¹ã‚¯ = 18å®Ÿé¨“ â†’ ç´„15-30åˆ†

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ç’°å¢ƒã‚¨ãƒ©ãƒ¼

```bash
# condaç’°å¢ƒãŒæœ‰åŠ¹ã‹ç¢ºèª
conda env list

# ç’°å¢ƒã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
conda run -n icl_task_vectors python -u -m scripts.experiments.token_length_analysis_v2
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³

```bash
# GPUãƒ¡ãƒ¢ãƒªç¢ºèª
nvidia-smi

# 1ãƒ¢ãƒ‡ãƒ«ãšã¤å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã« experiments_config.py ã‚’èª¿æ•´
```

### sacrebleu not found

```bash
# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
conda activate icl_task_vectors
pip install sacrebleu
```

## ğŸ“š é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

- `scripts/experiments/token_length_analysis_v2.py`: ãƒ¡ã‚¤ãƒ³å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `scripts/experiments/visualize_token_length_unified.py`: çµ±åˆå¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `core/experiments_config.py`: ãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã®è¨­å®š
- `run_token_analysis_v2.sh`: å®Ÿè¡Œç”¨ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

## âœ¨ V1ã‹ã‚‰ã®ä¸»ãªå¤‰æ›´ç‚¹

| é …ç›® | V1 | V2 |
|------|----|----|
| ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯ | æ‰‹å‹•æŒ‡å®š | experiments_config.pyã‹ã‚‰è‡ªå‹• |
| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Accuracyã®ã¿ | chrF, COMETï¼ˆAccuracyã‚‚å†…éƒ¨è¨ˆç®—ï¼‰ |
| å¯è¦–åŒ– | å€‹åˆ¥ã‚°ãƒ©ãƒ•å¤šæ•° | çµ±åˆã•ã‚ŒãŸå›³ï¼ˆchrF & COMETï¼‰ |
| ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›² | 0-10, 10-20, 20-30 | 0-5, 5-10, 10-15, 15-20 |
| ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ« | æ—¢å­˜å®Ÿè£…ã‚’åˆ©ç”¨ | æ—¢å­˜å®Ÿè£…ã‚’åˆ©ç”¨ï¼ˆå¤‰æ›´ãªã—ï¼‰ |

---

**æ¨å¥¨**: V2ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ï¼
